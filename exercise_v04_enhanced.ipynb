{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33774ce4-9445-49a6-b6fd-4d20ba662582",
   "metadata": {},
   "source": [
    "# PDF Processing via Enhanced Open-Source VLM\n",
    "## Optimized for Google Colab with High Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6ac96-c8fc-464b-a2b4-b8c679f0a9f8",
   "metadata": {},
   "source": [
    "## 0. Setting your Name and Email\n",
    "\n",
    "Please starting by putting your name and email in the following variables - please stick to the required format i.e. NAME_SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ecf101-81e3-4ee8-ba64-17ad4fd11273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE YOUR NAME_SURNAME HERE, AS WELL AS YOUR EMAIL WITH WHICH YOU LOGGED IN INTO CELONIS\n",
    "MY_NAME = 'SCHUMANN'\n",
    "MY_EMAIL = 'schumann.marvin@outlook.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84751d2e-8877-45e5-bc6b-95ef9f944415",
   "metadata": {},
   "source": [
    "## 1. Installing and importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5981996",
   "metadata": {},
   "outputs": [],
   "source": "# Run the first time you execute the script and then comment it out again.\n!pip install --extra-index-url=https://pypi.celonis.cloud/ pycelonis\n!pip install nbformat\n\n# Install poppler for PDF processing (required on Colab)\nimport sys\nif 'google.colab' in sys.modules:\n    !apt-get update -qq\n    !apt-get install -y -qq poppler-utils\n    print(\"‚úÖ Poppler installed for PDF support!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fd0841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ENHANCED OPEN-SOURCE INVOICE EXTRACTION\n",
    "# Model: Qwen2-VL-7B-Instruct (4-bit quantized)\n",
    "# Optimized for: Google Colab Free Tier (~12-16GB RAM)\n",
    "# Key Features:\n",
    "# - Validation & retry logic\n",
    "# - Better prompt engineering\n",
    "# - Post-processing validation\n",
    "# - 95%+ accuracy target\n",
    "# ============================================================\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install package if not already installed\"\"\"\n",
    "    try:\n",
    "        __import__(package.split('[')[0].replace('-', '_'))\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "\n",
    "# Detect environment\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "print(f\"Environment: {'Google Colab' if IS_COLAB else 'Local'}\")\n",
    "\n",
    "# Core packages\n",
    "packages = [\n",
    "    \"pillow\",\n",
    "    \"pdf2image\",\n",
    "    \"pandas\",\n",
    "    \"tqdm\",\n",
    "    \"torch\",\n",
    "    \"transformers>=4.37.0\",\n",
    "    \"accelerate\",\n",
    "    \"bitsandbytes\",  # For 4-bit quantization\n",
    "    \"qwen-vl-utils\",  # Qwen2-VL utilities\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    install_package(pkg)\n",
    "\n",
    "print(\"‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fdf2f-0447-4483-b952-b47655f8b555",
   "metadata": {},
   "source": [
    "## 2. Extract information from Invoices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f2cdd-821d-41a8-9fab-3c1df77ef017",
   "metadata": {},
   "source": [
    "This is the section you will need to fill in. Your code should create the following:\n",
    "- **a pandas dataframe called df that includes the extracted information**.\n",
    "- **the dataframe should contain a column called 'po_reference' that contains the reference to the PO**\n",
    "- **the values in the column 'po_reference' should be a 11-char long strings. Use left padding with zeros where needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddd6c1",
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# SECTION 2: ENHANCED INVOICE EXTRACTION\n# Using Qwen2-VL-7B-Instruct with validation & retry\n# ============================================================\n\nimport os\nimport re\nimport json\nfrom pathlib import Path\nfrom typing import Dict, List, Optional\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom pdf2image import convert_from_path\nimport torch\nfrom transformers import Qwen2VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\n\nprint(\"‚úÖ Packages loaded!\")\n\n# ==================== CONFIGURATION ====================\n\n# Auto-detect path for Colab or local\nif 'google.colab' in sys.modules:\n    # Check if cloned repo exists\n    if Path(\"/content/orbit_challenge/Invoices\").exists():\n        INVOICE_DIR = Path(\"/content/orbit_challenge/Invoices\")\n    else:\n        INVOICE_DIR = Path(\"/content/Invoices\")\nelse:\n    INVOICE_DIR = Path(\"/Users/marvinschumann/orbit_challenge/Invoices\")\n\nMODEL_ID = \"Qwen/Qwen2-VL-7B-Instruct\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Lower DPI to reduce memory usage (200 is good quality, uses less memory)\nPDF_DPI = 200\n# Maximum image dimensions to prevent OOM\nMAX_IMAGE_SIZE = (1600, 1600)\n\nREQUIRED_FIELDS = [\n    \"vendor_name\",\n    \"vendor_address\",\n    \"payment_terms\",\n    \"invoice_value\",\n    \"company_code\",\n    \"po_reference\",\n    \"invoice_id\"\n]\n\n# ==================== HELPER FUNCTIONS ====================\n\ndef resize_image_if_needed(image: Image.Image, max_size: tuple = MAX_IMAGE_SIZE) -> Image.Image:\n    \"\"\"Resize image if it exceeds max dimensions while maintaining aspect ratio\"\"\"\n    if image.width > max_size[0] or image.height > max_size[1]:\n        image.thumbnail(max_size, Image.Resampling.LANCZOS)\n        print(f\"    üìê Resized to {image.width}x{image.height} to save memory\")\n    return image\n\ndef load_invoice_pages(invoice_dir: Path) -> List[Dict]:\n    \"\"\"Load all invoice pages as images\"\"\"\n    pages = []\n    files = sorted([p for p in invoice_dir.iterdir() if p.is_file()])\n    \n    for file_path in tqdm(files, desc=\"üìÇ Loading invoices\"):\n        suffix = file_path.suffix.lower()\n        invoice_id = file_path.stem\n        \n        try:\n            if suffix == \".pdf\":\n                # Use lower DPI to reduce memory usage\n                images = convert_from_path(str(file_path), dpi=PDF_DPI, fmt=\"png\")\n                for idx, img in enumerate(images, start=1):\n                    img = img.convert(\"RGB\")\n                    img = resize_image_if_needed(img)\n                    pages.append({\n                        \"invoice_id\": invoice_id,\n                        \"page_index\": idx,\n                        \"image\": img,\n                    })\n            elif suffix in {\".png\", \".jpg\", \".jpeg\"}:\n                img = Image.open(file_path).convert(\"RGB\")\n                img = resize_image_if_needed(img)\n                pages.append({\n                    \"invoice_id\": invoice_id,\n                    \"page_index\": 1,\n                    \"image\": img,\n                })\n        except Exception as e:\n            print(f\"‚ùå Error loading {file_path.name}: {e}\")\n    \n    return pages\n\ndef sanitize_po_reference(po_value: str) -> str:\n    \"\"\"Extract digits and zero-pad to 11 characters\"\"\"\n    digits = re.sub(r\"\\D\", \"\", po_value or \"\")\n    return digits.zfill(11) if digits else \"00000000000\"\n\ndef validate_extraction(data: Dict) -> tuple[bool, List[str]]:\n    \"\"\"Validate extraction quality and return issues\"\"\"\n    issues = []\n    \n    # Check for empty critical fields\n    critical_fields = [\"vendor_name\", \"invoice_value\", \"po_reference\"]\n    for field in critical_fields:\n        if not data.get(field, \"\").strip():\n            issues.append(f\"Missing {field}\")\n    \n    # Validate invoice_value format - accept both currency symbols and numeric values\n    inv_val = data.get(\"invoice_value\", \"\")\n    if inv_val:\n        # Check if it has either currency symbol OR is a valid number\n        has_currency = bool(re.search(r'[‚Ç¨$¬£¬•]', inv_val))\n        has_number = bool(re.search(r'\\d+\\.?\\d*', inv_val))\n        if not has_number:\n            issues.append(\"Invalid invoice_value format\")\n    \n    # Validate PO reference has digits\n    po_ref = data.get(\"po_reference\", \"\")\n    if po_ref and not re.search(r'\\d', po_ref):\n        issues.append(\"PO reference has no digits\")\n    \n    return len(issues) == 0, issues\n\n# ==================== EXTRACTION PROMPTS ====================\n\nEXTRACTION_PROMPT = \"\"\"Analyze this invoice image and extract the following information with EXTREME ACCURACY.\n\nReturn ONLY a valid JSON object with these exact fields:\n\n{\n  \"vendor_name\": \"<company name providing goods/services>\",\n  \"vendor_address\": \"<complete address of the vendor>\",\n  \"payment_terms\": \"<payment terms and conditions>\",\n  \"invoice_value\": \"<TOTAL amount INCLUDING VAT/tax with currency symbol>\",\n  \"company_code\": \"<company code or customer code>\",\n  \"po_reference\": \"<purchase order number - extract the full PO number>\",\n  \"invoice_id\": \"<invoice number or invoice ID>\"\n}\n\nCRITICAL RULES:\n1. Return ONLY the JSON object - no markdown, no code blocks, no explanation\n2. For invoice_value: Use the TOTAL/FINAL amount WITH tax (look for \"Total\", \"Amount Due\", \"Grand Total\")\n3. For po_reference: Extract the COMPLETE PO number (e.g., \"PO-586652\" ‚Üí \"586652\")\n4. Use empty string \"\" for fields not found\n5. All string values must be double-quoted\n6. Be EXTREMELY accurate with numbers and codes - double-check each field\n\nExtract the data now:\"\"\"\n\nRETRY_PROMPT = \"\"\"The previous extraction had errors. Please re-analyze this invoice MORE CAREFULLY.\n\nFocus on these specific fields:\n- vendor_name: The company sending the invoice (usually at the top)\n- invoice_value: The FINAL TOTAL amount to pay (including tax/VAT)\n- po_reference: Purchase Order number (look for \"PO\", \"P.O.\", \"Purchase Order\")\n- company_code: Customer code or company code\n\nReturn ONLY a valid JSON object:\n\n{\n  \"vendor_name\": \"...\",\n  \"vendor_address\": \"...\",\n  \"payment_terms\": \"...\",\n  \"invoice_value\": \"...\",\n  \"company_code\": \"...\",\n  \"po_reference\": \"...\",\n  \"invoice_id\": \"...\"\n}\n\nExtract carefully:\"\"\"\n\n# ==================== MODEL INITIALIZATION ====================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üöÄ INITIALIZING QWEN2-VL-7B-INSTRUCT (4-bit)\")\nprint(\"=\"*70)\n\n# Load model with 4-bit quantization for Colab\nmodel = Qwen2VLForConditionalGeneration.from_pretrained(\n    MODEL_ID,\n    torch_dtype=\"auto\",\n    device_map=\"auto\",\n    load_in_4bit=True if DEVICE == \"cuda\" else False,\n)\n\nprocessor = AutoProcessor.from_pretrained(MODEL_ID)\n\nprint(f\"‚úÖ Model loaded on {DEVICE}\")\n\n# Clear any cached memory\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB total\")\n\n# ==================== EXTRACTION FUNCTION ====================\n\ndef extract_with_qwen(image: Image.Image, invoice_id: str, retry: bool = False) -> Dict:\n    \"\"\"Extract data using Qwen2-VL with validation and retry\"\"\"\n    \n    prompt = RETRY_PROMPT if retry else EXTRACTION_PROMPT\n    \n    try:\n        # Clear GPU cache before processing\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        # Prepare messages for Qwen2-VL\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"image\", \"image\": image},\n                    {\"type\": \"text\", \"text\": prompt},\n                ],\n            }\n        ]\n        \n        # Prepare inputs\n        text = processor.apply_chat_template(\n            messages, tokenize=False, add_generation_prompt=True\n        )\n        image_inputs, video_inputs = process_vision_info(messages)\n        inputs = processor(\n            text=[text],\n            images=image_inputs,\n            videos=video_inputs,\n            padding=True,\n            return_tensors=\"pt\",\n        )\n        inputs = inputs.to(DEVICE)\n        \n        # Generate\n        with torch.no_grad():\n            generated_ids = model.generate(\n                **inputs,\n                max_new_tokens=512,\n                temperature=0.1,\n                top_p=0.9,\n            )\n        \n        generated_ids_trimmed = [\n            out_ids[len(in_ids):] \n            for in_ids, out_ids in zip(inputs.input_ids, generated_ids)\n        ]\n        \n        response_text = processor.batch_decode(\n            generated_ids_trimmed,\n            skip_special_tokens=True,\n            clean_up_tokenization_spaces=False\n        )[0].strip()\n        \n        # Clean response\n        if response_text.startswith(\"```\"):\n            response_text = re.sub(r\"```(?:json)?\\n?\", \"\", response_text)\n            response_text = response_text.strip(\"`\")\n        \n        # Extract JSON\n        json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n        if json_match:\n            response_text = json_match.group(0)\n        \n        data = json.loads(response_text)\n        \n        # Ensure all fields exist\n        for field in REQUIRED_FIELDS:\n            if field not in data:\n                data[field] = \"\"\n        \n        # Clear GPU cache after successful processing\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        \n        return data\n        \n    except torch.cuda.OutOfMemoryError as e:\n        print(f\"    üí• GPU out of memory for {invoice_id} - clearing cache and skipping\")\n        if torch.cuda.is_available():\n            torch.cuda.empty_cache()\n        return {field: \"\" for field in REQUIRED_FIELDS}\n    except json.JSONDecodeError as e:\n        print(f\"    ‚ö†Ô∏è  JSON parse error for {invoice_id}\")\n        return {field: \"\" for field in REQUIRED_FIELDS}\n    except Exception as e:\n        print(f\"    ‚ùå Error for {invoice_id}: {str(e)[:100]}\")\n        return {field: \"\" for field in REQUIRED_FIELDS}\n\n# ==================== MAIN PIPELINE ====================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üöÄ INVOICE EXTRACTION - QWEN2-VL-7B\")\nprint(\"=\"*70)\n\n# Validate\nif not INVOICE_DIR.exists():\n    print(f\"\\n‚ùå ERROR: Directory not found: {INVOICE_DIR}\")\n    raise FileNotFoundError(f\"Directory not found: {INVOICE_DIR}\")\n\n# Load invoices\ninvoice_pages = load_invoice_pages(INVOICE_DIR)\nprint(f\"\\n‚úÖ Loaded {len(invoice_pages)} page(s) from {len(set(p['invoice_id'] for p in invoice_pages))} invoice(s)\")\n\n# Extract with validation and retry\nprint(\"\\n\" + \"=\"*70)\nprint(\"üîç EXTRACTING DATA WITH VALIDATION\")\nprint(\"=\"*70)\n\npage_results = []\n\nfor page in invoice_pages:\n    print(f\"\\nüìÑ {page['invoice_id']} (page {page['page_index']}):\")\n    print(f\"  üìê Image size: {page['image'].width}x{page['image'].height}\")\n    print(\"  ü§ñ Extracting with Qwen2-VL...\")\n    \n    # First attempt\n    result = extract_with_qwen(page['image'], page['invoice_id'], retry=False)\n    result['invoice_id'] = page['invoice_id']\n    \n    # Validate\n    is_valid, issues = validate_extraction(result)\n    \n    if not is_valid:\n        print(f\"  ‚ö†Ô∏è  Validation failed: {', '.join(issues)}\")\n        print(\"  üîÑ Retrying with stricter prompt...\")\n        \n        # Retry\n        result = extract_with_qwen(page['image'], page['invoice_id'], retry=True)\n        result['invoice_id'] = page['invoice_id']\n        \n        is_valid, issues = validate_extraction(result)\n        if is_valid:\n            print(\"  ‚úÖ Retry successful!\")\n        else:\n            print(f\"  ‚ö†Ô∏è  Still has issues: {', '.join(issues)}\")\n    else:\n        print(\"  ‚úÖ Extraction validated!\")\n    \n    # Show filled fields\n    filled = sum(1 for f in REQUIRED_FIELDS if result.get(f, \"\").strip())\n    print(f\"  üìä Extracted {filled}/{len(REQUIRED_FIELDS)} fields\")\n    \n    page_results.append(result)\n\n# Consolidate multi-page invoices\nprint(\"\\nüìä Consolidating results...\")\nconsolidated = {}\n\nfor entry in page_results:\n    inv_id = entry[\"invoice_id\"]\n    \n    if inv_id not in consolidated:\n        consolidated[inv_id] = {field: \"\" for field in REQUIRED_FIELDS}\n        consolidated[inv_id][\"invoice_id\"] = inv_id\n    \n    # Merge: prefer non-empty values\n    for field in REQUIRED_FIELDS:\n        if not consolidated[inv_id][field] and entry.get(field):\n            consolidated[inv_id][field] = entry[field]\n\n# Create DataFrame\nrecords = list(consolidated.values())\n\nfor record in records:\n    # Sanitize PO reference to 11 digits\n    record[\"po_reference\"] = sanitize_po_reference(record[\"po_reference\"])\n    \n    # Ensure all values are strings\n    for field in REQUIRED_FIELDS:\n        record[field] = str(record.get(field, \"\")).strip()\n\ndf = pd.DataFrame(records, columns=REQUIRED_FIELDS)\n\n# ==================== RESULTS ====================\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ EXTRACTION COMPLETE\")\nprint(\"=\"*70)\n\nprint(f\"\\nüìã Extracted {len(df)} invoices:\\n\")\nprint(df.to_string(index=False))\n\n# Detailed results per invoice\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìä DETAILED RESULTS\")\nprint(\"=\"*70)\n\nfor idx, row in df.iterrows():\n    inv_id = row['invoice_id']\n    print(f\"\\nüìÑ {inv_id}:\")\n    for field in REQUIRED_FIELDS:\n        value = row[field]\n        status = \"‚úÖ\" if value and value != \"00000000000\" else \"‚ùå\"\n        print(f\"  {status} {field}: {value if value else '(empty)'}\")\n\n# Quality check\nempty_per_row = df.apply(lambda row: sum(v == \"\" or v == \"00000000000\" for v in row), axis=1)\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"üìà SUMMARY\")\nprint(\"=\"*70)\n\nif empty_per_row.sum() == 0:\n    print(\"\\n‚úÖ Perfect! All fields extracted successfully\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Warning: {empty_per_row.sum()} empty/default fields detected\")\n    problem_invoices = df[empty_per_row > 0]\n    print(\"\\nInvoices needing attention:\")\n    print(problem_invoices[[\"invoice_id\", \"po_reference\"]].to_string(index=False))\n\n# PO reference validation\ninvalid_po = df[df[\"po_reference\"].str.len() != 11]\nif len(invalid_po) > 0:\n    print(f\"\\n‚ö†Ô∏è  Warning: {len(invalid_po)} PO references not 11 chars\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"‚úÖ READY FOR PUSH.IPYNB\")\nprint(\"=\"*70)\nprint(\"\\nNext: Run %run push.ipynb\")"
  },
  {
   "cell_type": "markdown",
   "id": "f5640b28-8710-4cee-a0c6-7c3e578dd307",
   "metadata": {},
   "source": [
    "## 3. Pushing Data back to Data Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9a4a4-54a7-413e-97d4-0b8e38ab0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run push.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}