{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33774ce4-9445-49a6-b6fd-4d20ba662582",
   "metadata": {
    "id": "33774ce4-9445-49a6-b6fd-4d20ba662582"
   },
   "source": [
    "# PDF Processing via LLMaaS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e6ac96-c8fc-464b-a2b4-b8c679f0a9f8",
   "metadata": {
    "id": "89e6ac96-c8fc-464b-a2b4-b8c679f0a9f8"
   },
   "source": [
    "## 0. Setting your Name and Email\n",
    "\n",
    "Please starting by putting your name and email in the following variables - please stick to the required format i.e. NAME_SURNAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13ecf101-81e3-4ee8-ba64-17ad4fd11273",
   "metadata": {
    "executionInfo": {
     "elapsed": 49,
     "status": "ok",
     "timestamp": 1753731379955,
     "user": {
      "displayName": "Ahmed Ayadi",
      "userId": "12498121954969053451"
     },
     "user_tz": 240
    },
    "id": "13ecf101-81e3-4ee8-ba64-17ad4fd11273"
   },
   "outputs": [],
   "source": [
    "# WRITE YOUR NAME_SURNAME HERE, AS WELL AS YOUR EMAIL WITH WHICH YOU LOGGED IN INTO CELONIS\n",
    "MY_NAME = 'SCHUMANN'\n",
    "MY_EMAIL = 'schumann.marvin@outlook.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84751d2e-8877-45e5-bc6b-95ef9f944415",
   "metadata": {
    "id": "84751d2e-8877-45e5-bc6b-95ef9f944415"
   },
   "source": [
    "## 1. Installing and importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22154ae-c346-429d-be6e-0935c7fceaa6",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1753731380549,
     "user": {
      "displayName": "Ahmed Ayadi",
      "userId": "12498121954969053451"
     },
     "user_tz": 240
    },
    "id": "c22154ae-c346-429d-be6e-0935c7fceaa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.celonis.cloud/\n",
      "Requirement already satisfied: pycelonis in /opt/anaconda3/lib/python3.12/site-packages (2.14.0)\n",
      "Requirement already satisfied: pycelonis-core>=2.10.3 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (2.10.3)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (1.5.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (14.0.2)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (4.67.1)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (6.0.1)\n",
      "Requirement already satisfied: saolapy>=0.3.3.dev0 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (0.3.3)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis) (23.2)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->pycelonis) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->pycelonis) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->pycelonis) (2025.1)\n",
      "Requirement already satisfied: httpx>=0.28.0 in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis-core>=2.10.3->pycelonis) (0.28.1)\n",
      "Requirement already satisfied: pydantic in /opt/anaconda3/lib/python3.12/site-packages (from pycelonis-core>=2.10.3->pycelonis) (2.11.4)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/lib/python3.12/site-packages (from httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.1->pandas>=1.4.0->pycelonis) (1.17.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (1.3.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5 in /opt/anaconda3/lib/python3.12/site-packages (from anyio->httpx>=0.28.0->pycelonis-core>=2.10.3->pycelonis) (4.13.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->pycelonis-core>=2.10.3->pycelonis) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->pycelonis-core>=2.10.3->pycelonis) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from pydantic->pycelonis-core>=2.10.3->pycelonis) (0.4.0)\n",
      "Requirement already satisfied: nbformat in /opt/anaconda3/lib/python3.12/site-packages (5.9.2)\n",
      "Requirement already satisfied: fastjsonschema in /opt/anaconda3/lib/python3.12/site-packages (from nbformat) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /opt/anaconda3/lib/python3.12/site-packages (from nbformat) (4.19.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/anaconda3/lib/python3.12/site-packages (from nbformat) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from nbformat) (5.14.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/anaconda3/lib/python3.12/site-packages (from jsonschema>=2.6->nbformat) (0.10.6)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from jupyter-core->nbformat) (3.10.0)\n"
     ]
    }
   ],
   "source": [
    "#Run the first time you execute the script and then comment it out again.\n",
    "!pip install --extra-index-url=https://pypi.celonis.cloud/ pycelonis\n",
    "!pip install nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61124ab8-c1b6-4744-b678-ff8a137df3cb",
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1753742647957,
     "user": {
      "displayName": "Ahmed Ayadi",
      "userId": "12498121954969053451"
     },
     "user_tz": 240
    },
    "id": "61124ab8-c1b6-4744-b678-ff8a137df3cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.12/site-packages (11.2.1)\n",
      "Collecting einops\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.22-py3-none-any.whl.metadata (63 kB)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (from timm) (2.7.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (from timm) (0.22.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/lib/python3.12/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /opt/anaconda3/lib/python3.12/site-packages (from timm) (0.36.0)\n",
      "Requirement already satisfied: safetensors in /opt/anaconda3/lib/python3.12/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch->timm) (80.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.12/site-packages (from torch->timm) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch->timm) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision->timm) (11.2.1)\n",
      "Downloading timm-1.0.22-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.22\n"
     ]
    }
   ],
   "source": [
    "# Step 1 – environment setup\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def ensure_package(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "# Core packages required downstream\n",
    "for pkg_name in [\n",
    "    \"torch\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"pdf2image\",\n",
    "    \"pandas\",\n",
    "    \"tqdm\",\n",
    "    \"numpy\",\n",
    "    \"einops\",\n",
    "    \"timm\"\n",
    "]:\n",
    "    ensure_package(pkg_name)\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from pdf2image import convert_from_path\n",
    "from transformers import AutoModelForCausalLM, AutoProcessor\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266fdf2f-0447-4483-b952-b47655f8b555",
   "metadata": {
    "id": "266fdf2f-0447-4483-b952-b47655f8b555"
   },
   "source": [
    "## 2. Extract information from Invoices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5f2cdd-821d-41a8-9fab-3c1df77ef017",
   "metadata": {
    "id": "dc5f2cdd-821d-41a8-9fab-3c1df77ef017"
   },
   "source": [
    "This is the section you will need to fill in. Your code should create the following\n",
    "- **a pandas dataframe called df that includes the extracted information**.\n",
    "- **the dataframe should contain a column called 'po_reference' that contains the reference to the PO**\n",
    "- **the values in the column 'po_reference' should be a 11-char long strings. Use left padding with zeros where needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddd6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading invoices: 100%|██████████| 5/5 [00:03<00:00,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 page(s) from 5 invoice file(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 2 – load invoice pages as images\n",
    "\n",
    "INVOICE_DIR = Path(\"/Users/marvinschumann/orbit_challenge/Invoices\")\n",
    "POPPLER_PATH = os.getenv(\"POPPLER_PATH\")  # set if poppler isn't on PATH\n",
    "\n",
    "def load_invoice_pages(invoice_dir: Path) -> list[dict]:\n",
    "    pages = []\n",
    "    files = sorted([p for p in invoice_dir.iterdir() if p.is_file()])\n",
    "    for file_path in tqdm(files, desc=\"Loading invoices\"):\n",
    "        suffix = file_path.suffix.lower()\n",
    "        invoice_id = file_path.stem.strip()\n",
    "        if suffix == \".pdf\":\n",
    "            images = convert_from_path(\n",
    "                str(file_path),\n",
    "                dpi=200,\n",
    "                poppler_path=POPPLER_PATH,\n",
    "                fmt=\"png\"\n",
    "            )\n",
    "            for idx, img in enumerate(images, start=1):\n",
    "                pages.append(\n",
    "                    {\n",
    "                        \"invoice_id\": invoice_id,\n",
    "                        \"page_index\": idx,\n",
    "                        \"image\": img.convert(\"RGB\"),\n",
    "                        \"source_path\": str(file_path),\n",
    "                    }\n",
    "                )\n",
    "        elif suffix in {\".png\", \".jpg\", \".jpeg\"}:\n",
    "            img = Image.open(file_path).convert(\"RGB\")\n",
    "            pages.append(\n",
    "                {\n",
    "                    \"invoice_id\": invoice_id,\n",
    "                    \"page_index\": 1,\n",
    "                    \"image\": img,\n",
    "                    \"source_path\": str(file_path),\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            print(f\"Skipping unsupported file: {file_path.name}\")\n",
    "    return pages\n",
    "\n",
    "invoice_pages = load_invoice_pages(INVOICE_DIR)\n",
    "print(f\"Loaded {len(invoice_pages)} page(s) from {len({p['invoice_id'] for p in invoice_pages})} invoice file(s).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393cf3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting data:   0%|          | 0/5 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Extracting data:  20%|██        | 1/5 [00:11<00:47, 11.80s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Extracting data:  40%|████      | 2/5 [00:16<00:23,  7.77s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Extracting data:  60%|██████    | 3/5 [00:19<00:11,  5.63s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Extracting data:  80%|████████  | 4/5 [00:25<00:05,  5.49s/it]Setting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\n",
      "Extracting data: 100%|██████████| 5/5 [00:31<00:00,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete for 5 pages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Steps 3 & 4 – initialize InternVL and extract invoice fields (enhanced)\n",
    "from transformers import AutoTokenizer, AutoImageProcessor, AutoModelForCausalLM\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "\n",
    "MODEL_ID = \"OpenGVLab/InternVL2-1B\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# model and processors\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "image_processor = AutoImageProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.float16 if DEVICE.type == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if DEVICE.type == \"cuda\" else None,\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "gen_config_dict = {\n",
    "    \"max_new_tokens\": 512,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_p\": 0.9,\n",
    "}\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    \"vendor_name\",\n",
    "    \"vendor_address\",\n",
    "    \"payment_terms\",\n",
    "    \"invoice_value\",\n",
    "    \"company_code\",\n",
    "    \"po_reference\",\n",
    "    \"invoice_id\",\n",
    "]\n",
    "\n",
    "FIELD_DESCRIPTIONS = {\n",
    "    \"vendor_name\": \"the legal name of the vendor or supplier\",\n",
    "    \"vendor_address\": \"the full postal address of the vendor\",\n",
    "    \"payment_terms\": \"the payment terms (e.g., Net 30, Due on receipt)\",\n",
    "    \"invoice_value\": \"the total invoice amount including currency symbol\",\n",
    "    \"company_code\": \"the company code associated with the purchase order\",\n",
    "    \"po_reference\": \"the purchase order reference or number\",\n",
    "    \"invoice_id\": \"the invoice number or identifier\",\n",
    "}\n",
    "\n",
    "FIELD_PROMPT_HINTS = {\n",
    "    \"vendor_name\": \"Return only the vendor's name (no invoice numbers).\",\n",
    "    \"vendor_address\": \"Return the full mailing address as shown on the invoice.\",\n",
    "    \"payment_terms\": \"Return the payment terms text exactly as printed.\",\n",
    "    \"invoice_value\": \"Return the total invoice amount including the currency symbol if present.\",\n",
    "    \"company_code\": \"Return the company code as printed (numbers only, no labels).\",\n",
    "    \"po_reference\": \"Return only the digits of the purchase order reference (no prefixes or text).\",\n",
    "    \"invoice_id\": \"Return the invoice number exactly as printed on the document.\",\n",
    "}\n",
    "\n",
    "FIELD_VALIDATORS = {\n",
    "    \"po_reference\": lambda value: bool(re.search(r\"\\d\", value)),\n",
    "    \"company_code\": lambda value: bool(re.search(r\"\\d\", value)),\n",
    "    \"invoice_value\": lambda value: bool(re.search(r\"\\d\", value)),\n",
    "    \"invoice_id\": lambda value: bool(re.search(r\"\\d\", value)),\n",
    "}\n",
    "\n",
    "INVALID_FIELD_STRINGS = {\n",
    "    \"\",\n",
    "    \"unknown\",\n",
    "    \"undefined\",\n",
    "    \"not provided\",\n",
    "    \"not applicable\",\n",
    "    \"n/a\",\n",
    "    \"na\",\n",
    "    \"none\",\n",
    "    \"null\",\n",
    "}\n",
    "\n",
    "PRIMARY_PROMPT = (\n",
    "    \"You are an expert invoice analyst. Carefully read the invoice image and return a JSON object \"\n",
    "    \"with the following keys: vendor_name, vendor_address, payment_terms, invoice_value, company_code, \"\n",
    "    \"po_reference, invoice_id. Use double quotes for all keys and string values. If a value is missing, \"\n",
    "    \"respond with the literal string UNKNOWN for that field. Do not add commentary or extra keys.\"\n",
    ")\n",
    "\n",
    "SINGLE_FIELD_PROMPT_TEMPLATE = (\n",
    "    \"You previously inspected this invoice. Provide the value for the field '{field}' ({description}). \"\n",
    "    \"Return a JSON object containing only the key '{field}' with its value. Use double quotes and \"\n",
    "    \"respond with the literal string UNKNOWN if the value cannot be determined.\"\n",
    ")\n",
    "\n",
    "MISSING_FIELDS_PROMPT_TEMPLATE = (\n",
    "    \"The following fields could not be confirmed: {fields}. Review the invoice image again and respond \"\n",
    "    \"with a JSON object that contains these keys only. Use double quotes and set any unknown value to \"\n",
    "    \"the literal string UNKNOWN.\"\n",
    ")\n",
    "\n",
    "MAX_PRIMARY_ATTEMPTS = 3\n",
    "MAX_FIELD_ATTEMPTS = 2\n",
    "\n",
    "def clean_response_text(text: str) -> str:\n",
    "    cleaned = text.strip()\n",
    "    if cleaned.startswith(\"```\"):\n",
    "        cleaned = re.sub(r\"^```(?:json)?\", \"\", cleaned, flags=re.IGNORECASE).strip()\n",
    "        cleaned = cleaned.rstrip(\"`\").strip()\n",
    "    cleaned = cleaned.replace(\"\\u201c\", '\"').replace(\"\\u201d\", '\"')\n",
    "    return cleaned\n",
    "\n",
    "def parse_json_response(raw_text: str, expected_fields=None) -> dict:\n",
    "    cleaned = clean_response_text(raw_text)\n",
    "    expected_fields = expected_fields or REQUIRED_FIELDS\n",
    "    try:\n",
    "        parsed = json.loads(cleaned)\n",
    "        if isinstance(parsed, list) and len(parsed) == 1 and isinstance(parsed[0], dict):\n",
    "            parsed = parsed[0]\n",
    "        if isinstance(parsed, dict):\n",
    "            return parsed\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    extracted = {}\n",
    "    for field in expected_fields:\n",
    "        pattern = rf'\"{field}\"\\s*:\\s*\"([^\"]*)\"'\n",
    "        match = re.search(pattern, cleaned)\n",
    "        if match:\n",
    "            extracted[field] = match.group(1)\n",
    "    return extracted\n",
    "\n",
    "def is_valid_field(value: str, field: str | None = None) -> bool:\n",
    "    if value is None:\n",
    "        return False\n",
    "    normalized = str(value).strip()\n",
    "    if not normalized or normalized.lower() in INVALID_FIELD_STRINGS:\n",
    "        return False\n",
    "    if field:\n",
    "        normalized_plain = normalized.lower().replace(\" \", \"\")\n",
    "        field_plain = field.replace(\"_\", \"\").lower()\n",
    "        if normalized_plain == field_plain:\n",
    "            return False\n",
    "        validator = FIELD_VALIDATORS.get(field)\n",
    "        if validator and not validator(normalized):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def merge_fields(target: dict, updates: dict) -> None:\n",
    "    for field, value in updates.items():\n",
    "        if field not in target or field == \"invoice_id\":\n",
    "            continue\n",
    "        if is_valid_field(value, field) and not is_valid_field(target.get(field, \"\"), field):\n",
    "            target[field] = str(value).strip()\n",
    "\n",
    "def get_missing_fields(record: dict) -> list:\n",
    "    return [\n",
    "        field\n",
    "        for field in REQUIRED_FIELDS\n",
    "        if field != \"invoice_id\" and not is_valid_field(record.get(field, \"\"), field)\n",
    "    ]\n",
    "\n",
    "def run_chat_once(pixel_values, prompt, history=None):\n",
    "    response = model.chat(\n",
    "        tokenizer=tokenizer,\n",
    "        pixel_values=pixel_values,\n",
    "        question=prompt,\n",
    "        history=history,\n",
    "        generation_config=gen_config_dict,\n",
    "    )\n",
    "    if isinstance(response, tuple) and len(response) == 2:\n",
    "        answer, new_history = response\n",
    "    else:\n",
    "        answer = response\n",
    "        new_history = history\n",
    "    return answer.strip(), new_history\n",
    "\n",
    "def extract_page_metadata(page_entry):\n",
    "    image = page_entry[\"image\"]\n",
    "    invoice_id = page_entry[\"invoice_id\"]\n",
    "    pixel_values = image_processor(images=image, return_tensors=\"pt\").pixel_values.to(DEVICE)\n",
    "\n",
    "    aggregated = {field: \"\" for field in REQUIRED_FIELDS}\n",
    "    aggregated[\"invoice_id\"] = invoice_id\n",
    "    raw_attempts = []\n",
    "    history = None\n",
    "\n",
    "    # Primary attempts\n",
    "    for attempt in range(1, MAX_PRIMARY_ATTEMPTS + 1):\n",
    "        response_text, history = run_chat_once(pixel_values, PRIMARY_PROMPT, history=None)\n",
    "        raw_attempts.append(\n",
    "            {\n",
    "                \"attempt_type\": \"primary\",\n",
    "                \"attempt\": attempt,\n",
    "                \"prompt\": PRIMARY_PROMPT,\n",
    "                \"response\": response_text,\n",
    "            }\n",
    "        )\n",
    "        parsed = parse_json_response(response_text)\n",
    "        merge_fields(aggregated, parsed)\n",
    "        if not get_missing_fields(aggregated):\n",
    "            break\n",
    "\n",
    "    missing = get_missing_fields(aggregated)\n",
    "\n",
    "    # Targeted follow-ups per missing field\n",
    "    for field in missing.copy():\n",
    "        description = FIELD_DESCRIPTIONS.get(field, field)\n",
    "        prompt = SINGLE_FIELD_PROMPT_TEMPLATE.format(field=field, description=description)\n",
    "        hint = FIELD_PROMPT_HINTS.get(field)\n",
    "        if hint:\n",
    "            prompt = f\"{prompt} {hint}\"\n",
    "        field_history = history  # reuse most recent history if available\n",
    "        for attempt in range(1, MAX_FIELD_ATTEMPTS + 1):\n",
    "            response_text, field_history = run_chat_once(pixel_values, prompt, history=field_history)\n",
    "            raw_attempts.append(\n",
    "                {\n",
    "                    \"attempt_type\": \"single_field\",\n",
    "                    \"field\": field,\n",
    "                    \"attempt\": attempt,\n",
    "                    \"prompt\": prompt,\n",
    "                    \"response\": response_text,\n",
    "                }\n",
    "            )\n",
    "            parsed = parse_json_response(response_text, expected_fields=[field])\n",
    "            merge_fields(aggregated, parsed)\n",
    "            if field not in get_missing_fields(aggregated):\n",
    "                break\n",
    "\n",
    "    missing = get_missing_fields(aggregated)\n",
    "\n",
    "    # Final multi-field prompt if any are still missing\n",
    "    if missing:\n",
    "        prompt = MISSING_FIELDS_PROMPT_TEMPLATE.format(fields=\", \".join(missing))\n",
    "        hint_text = \" \".join(filter(None, (FIELD_PROMPT_HINTS.get(field) for field in missing)))\n",
    "        if hint_text:\n",
    "            prompt = f\"{prompt} {hint_text}\"\n",
    "        response_text, _ = run_chat_once(pixel_values, prompt, history=history)\n",
    "        raw_attempts.append(\n",
    "            {\n",
    "                \"attempt_type\": \"missing_fields\",\n",
    "                \"fields\": list(missing),\n",
    "                \"prompt\": prompt,\n",
    "                \"response\": response_text,\n",
    "            }\n",
    "        )\n",
    "        parsed = parse_json_response(response_text, expected_fields=missing)\n",
    "        merge_fields(aggregated, parsed)\n",
    "\n",
    "    final_missing = get_missing_fields(aggregated)\n",
    "\n",
    "    result_record = {field: aggregated.get(field, \"\") for field in REQUIRED_FIELDS}\n",
    "    result_record[\"missing_fields\"] = final_missing\n",
    "    result_record[\"raw_attempts\"] = raw_attempts\n",
    "\n",
    "    enriched_entry = {\n",
    "        **page_entry,\n",
    "        **result_record,\n",
    "    }\n",
    "    # remove heavy pixel tensor to avoid retaining GPU memory\n",
    "    enriched_entry.pop(\"image\", None)\n",
    "    return enriched_entry\n",
    "\n",
    "page_results = [\n",
    "    extract_page_metadata(page)\n",
    "    for page in tqdm(invoice_pages, desc=\"Extracting data\")\n",
    "]\n",
    "\n",
    "print(f\"Extraction complete for {len(page_results)} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5b6917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vendor_name</th>\n",
       "      <th>vendor_address</th>\n",
       "      <th>payment_terms</th>\n",
       "      <th>invoice_value</th>\n",
       "      <th>company_code</th>\n",
       "      <th>po_reference</th>\n",
       "      <th>invoice_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5578 Vendor Street</td>\n",
       "      <td>Business District</td>\n",
       "      <td>Due within 30 days</td>\n",
       "      <td>€3,360.00</td>\n",
       "      <td>5578</td>\n",
       "      <td>000008568534</td>\n",
       "      <td>INV-2020-08-001247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vendor34</td>\n",
       "      <td>789 Vendor Street</td>\n",
       "      <td>Late payments may incur interest charges</td>\n",
       "      <td>£1,400.00</td>\n",
       "      <td>CompanyCode4</td>\n",
       "      <td>00000048334</td>\n",
       "      <td>INV-2020-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>00000000000</td>\n",
       "      <td>INV-2020-07-001853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vendor45</td>\n",
       "      <td>789 Vendor Street</td>\n",
       "      <td>Late payments may incur interest charges at 1....</td>\n",
       "      <td>€5,057.50</td>\n",
       "      <td>CompanyCode3</td>\n",
       "      <td>00000000181</td>\n",
       "      <td>INV-2021-001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vendor34</td>\n",
       "      <td>789 Vendor Street, Vendor City, State 54321</td>\n",
       "      <td>Due Dates: March 5, 2021 Due Dates: March 20, ...</td>\n",
       "      <td>€1,500.00</td>\n",
       "      <td>123456789</td>\n",
       "      <td>PO_123456789</td>\n",
       "      <td>INV-2021-002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          vendor_name                               vendor_address                                      payment_terms  \\\n",
       "0  5578 Vendor Street                            Business District                                 Due within 30 days   \n",
       "1            Vendor34                            789 Vendor Street           Late payments may incur interest charges   \n",
       "2                                                                                                                       \n",
       "3            Vendor45                            789 Vendor Street  Late payments may incur interest charges at 1....   \n",
       "4            Vendor34  789 Vendor Street, Vendor City, State 54321  Due Dates: March 5, 2021 Due Dates: March 20, ...   \n",
       "\n",
       "  invoice_value  company_code  po_reference           invoice_id  \n",
       "0     €3,360.00          5578  000008568534   INV-2020-08-001247  \n",
       "1     £1,400.00  CompanyCode4   00000048334         INV-2020-001  \n",
       "2                               00000000000   INV-2020-07-001853  \n",
       "3     €5,057.50  CompanyCode3   00000000181         INV-2021-001  \n",
       "4     €1,500.00     123456789  PO_123456789         INV-2021-002  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendor_name       0\n",
      "vendor_address    0\n",
      "payment_terms     0\n",
      "invoice_value     0\n",
      "company_code      0\n",
      "po_reference      0\n",
      "invoice_id        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 5 – consolidate page results into final dataframe\n",
    "\n",
    "def consolidate_invoice_pages(pages):\n",
    "    consolidated = {}\n",
    "    for entry in pages:\n",
    "        inv_id = entry[\"invoice_id\"]\n",
    "        if inv_id not in consolidated:\n",
    "            consolidated[inv_id] = {\n",
    "                field: \"\" for field in REQUIRED_FIELDS\n",
    "            }\n",
    "            consolidated[inv_id][\"invoice_id\"] = inv_id\n",
    "            consolidated[inv_id][\"raw_attempts\"] = []\n",
    "            consolidated[inv_id][\"missing_fields\"] = set()\n",
    "\n",
    "        consolidated_entry = consolidated[inv_id]\n",
    "\n",
    "        for field in REQUIRED_FIELDS:\n",
    "            if field == \"invoice_id\":\n",
    "                continue\n",
    "            candidate = str(entry.get(field, \"\")).strip()\n",
    "            if is_valid_field(candidate, field) and not is_valid_field(consolidated_entry.get(field, \"\"), field):\n",
    "                consolidated_entry[field] = candidate\n",
    "\n",
    "        consolidated_entry[\"raw_attempts\"].extend(entry.get(\"raw_attempts\", []))\n",
    "        consolidated_entry[\"missing_fields\"].update(entry.get(\"missing_fields\", []))\n",
    "\n",
    "    records = []\n",
    "    quality_issues = []\n",
    "    for inv_id, data in consolidated.items():\n",
    "        records.append({field: data.get(field, \"\") for field in REQUIRED_FIELDS})\n",
    "        unresolved = [\n",
    "            field for field in REQUIRED_FIELDS\n",
    "            if field != \"invoice_id\" and not is_valid_field(data.get(field, \"\"), field)\n",
    "        ]\n",
    "        if unresolved:\n",
    "            quality_issues.append({\"invoice_id\": inv_id, \"missing_fields\": unresolved})\n",
    "\n",
    "    return records, consolidated, quality_issues\n",
    "\n",
    "invoice_records, extraction_diagnostics, extraction_issues = consolidate_invoice_pages(page_results)\n",
    "\n",
    "df = pd.DataFrame(invoice_records, columns=REQUIRED_FIELDS)\n",
    "\n",
    "display(df)\n",
    "\n",
    "if extraction_issues:\n",
    "    print(\"Warning: Some invoices still have unresolved fields:\")\n",
    "    display(pd.DataFrame(extraction_issues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16edcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6 – normalize values and validate completeness\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def sanitize_po(po_value: str) -> str:\n",
    "    digits = re.sub(r\"\\D\", \"\", po_value or \"\")\n",
    "    return digits.zfill(11) if digits else \"\"\n",
    "\n",
    "df = df.copy()\n",
    "df[\"po_reference\"] = df[\"po_reference\"].apply(sanitize_po)\n",
    "\n",
    "validation_issues = []\n",
    "for _, row in df.iterrows():\n",
    "    missing = [\n",
    "        field for field in REQUIRED_FIELDS\n",
    "        if field != \"invoice_id\" and not is_valid_field(row.get(field, \"\"))\n",
    "    ]\n",
    "    if missing:\n",
    "        validation_issues.append({\n",
    "            \"invoice_id\": row[\"invoice_id\"],\n",
    "            \"missing_fields\": missing,\n",
    "        })\n",
    "\n",
    "if validation_issues:\n",
    "    print(\"Extraction validation failed. Review diagnostics below.\")\n",
    "    display(pd.DataFrame(validation_issues))\n",
    "    if 'extraction_diagnostics' in globals():\n",
    "        debug_rows = []\n",
    "        for issue in validation_issues:\n",
    "            diag = extraction_diagnostics.get(issue[\"invoice_id\"], {})\n",
    "            debug_rows.append({\n",
    "                \"invoice_id\": issue[\"invoice_id\"],\n",
    "                \"missing_fields\": issue[\"missing_fields\"],\n",
    "                \"raw_attempts\": diag.get(\"raw_attempts\", []),\n",
    "            })\n",
    "        print(\"Detailed raw attempts for problematic invoices:\")\n",
    "        display(pd.DataFrame(debug_rows))\n",
    "    raise ValueError(\"Not all required invoice fields could be extracted automatically.\")\n",
    "\n",
    "print(\"All invoice records passed validation.\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5640b28-8710-4cee-a0c6-7c3e578dd307",
   "metadata": {
    "id": "f5640b28-8710-4cee-a0c6-7c3e578dd307"
   },
   "source": [
    "## 3. Pushing Data back to Data Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b9a4a4-54a7-413e-97d4-0b8e38ab0d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run push.ipynb"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
